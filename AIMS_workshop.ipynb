{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ba11f0",
   "metadata": {},
   "source": [
    "# IBM-CHCP-AIMS Workshop on The Theory of Quantum Learning Algorithms\n",
    "## Quantum Machine Learning Practical Session with Qiskit\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "0. [Introduction to the QML Practical Session with Qiskit!](#welcome)<br>\n",
    "0.1. [Verifying Qiskit installation and checking version](#install)<br>\n",
    "0.2. [Import Modules and Download IRIS Dataset](#import)<br>\n",
    "0.3. [Overview of the QML Pipeline Adapted from Qiskit Patterns](#introduction)<br>\n",
    "2. [Loading the Classical Iris Dataset onto A Quantum Circuit](#cml)<br>\n",
    "A. [ Data Analysis and Description](#data_analysis)<br>\n",
    "B. [Splitting Data](#data_split)<br>\n",
    "3. [Training a Quantum Machine Learning Model](#prep)<br>\n",
    "A. [Data Encoding Using the ZFM](#data_encoding)<br>\n",
    "B. [Parameterized Quantum Circuit](#ansatz)\n",
    "4. [Optimise the Problem for Quantum Execution](#optimise)<br>\n",
    "5. [Execute Using Qiskit Primitives](#execute)<br>\n",
    "6. [Post-Process Results to Extract Classical Data](#post)<br>\n",
    "7. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179bd42",
   "metadata": {},
   "source": [
    "### 0. Introduction to the QML Practical Session with Qiskit! <a id=\"welcome\"></a>\n",
    "Welcome to the Quantum Machine Learning (QML) Hands-on Workshop curated for the IBM-CHCP-AIMS Workshop on The Theory of Quantum Learning Algorithms! In this session we demonstate how IBM Research scientists and engineers leverage Qiskit Patterns to execute QML workflows. In particular, we demonstrate an implementation of hybrid quantum classical model in labeling unseen images from the well-known IRIS dataset containing three iris species: Setosa, Versicolour, and Virginica.\n",
    "\n",
    "QML can be described as a quantum computing paradigm that applies quantum mechanical phenomena such as superposition and entanglement to enable researchers to extract insights and patterns from data.â€‹ At IBM Research, we exploit QML across multiple disciplinaries such healthcare, finance, and chemistry, to augment or complement existing classical workflows.\n",
    "\n",
    "In this notebook, we implement the steps in building efficient QML workflows by leveraging the high performance of quantum computers through this pipeline we show how by fine tuning parameters in the quantum algorithm using the Qiskit software development kit (SDK) which follows Qiskit Patterns can be useful in mitigating the bottlenecks that arise in quantum hardware.\n",
    "\n",
    "The Qiskit SDK is a fundamental toolkit for performing quantum experiments. We begin verifying that Qiskit 2.x is installed and setup the required modules for visualising data. Then, we ensure that the IRIS dataset is stored in our local environment.\n",
    "#### 0.1. Verifying Qiskit installation and checking version <a id=\"install\"></a>\n",
    "\n",
    "In the below cells, we check the Qiskit version. The minimum version required to run workloads on the new IBM Quantum Platform released in July 2025 is 2.0.0. We then download IRIS dataset using $\\texttt{pip}$\n",
    "\n",
    "In the following section, we implement the QML workflow, in which the classical data  are encoded to quantum states, data encoding is typically the first step in the QML pipeline. The full methodology follows the Qiskit Pattern framework as illustrated in the figure below:\n",
    "1. Mapping classical inputs to a quantum problem.\n",
    "2. Optimising the problem for execution on available quantum systems.\n",
    "3. Executing quantum circuits on simulators and hardware devices using the Qiskit Runtime primitives.\n",
    "4. Post-processing, returning the result in classical format.\n",
    "<p style=\"text-align:center;\">\n",
    "    <img src=\"images/qiskit_patterns.png\" />\n",
    "</p>\n",
    "<p style=\"text-align:center;\">\n",
    "    Figure 0.1. illustrating the Qiskit Pattern framework used in classifying iris species using a QNN. \n",
    "</p>\n",
    "To investigate QML further, we encourage you to visit the  <a href=https://quantum.cloud.ibm.com/learning/en/courses/quantum-machine-learning/introduction> Quantum Machine Learning course material</a> by IBM Quantum. For now, let's verify that we have Qiskit installed on our devices. If you do not have Qiskit on your machine, you can uncomment the cell below to install it, among other modules that we will be using moving forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install qiskit qiskit-machine-learning \n",
    "# %pip seaborn scikit-learn pandas matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d61779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit\n",
    "print(f\"Qiskit version: {qiskit.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5f0a3d",
   "metadata": {},
   "source": [
    "#### 0.2. Import Modules <a id=\"import\"></a>\n",
    "\n",
    "\n",
    "Qiskit is an open-source SDK created by IBM Research to enable quantum researchers and developers to programmatically interface with IBM Quantum hardware and simulators. Over the years, Qiskit has evolved to include powerful modules like Qiskit Addons and Qiskit Functions, which expedite the development of quantum algorithms. Among the Qiskit Functions is the $\\texttt{transpiler}$ package, which interprets quantum circuits and optimizes the conversion of abstract qubits to specific qubits on the hardware devices. Because our QML pipeline implements a classical-quantum hybrid stream, we can also leverage common Python modules to optimize certain parts of our workflow. \n",
    "\n",
    "To run workflows on IBM Quantum hardware, researchers at IBM Research use Qiskit Runtime, which is the architecture that streamlines computations requiring multiple iterations. Qiskit Runtime enables algorithms to execute significantly faster. \n",
    "\n",
    "For the purpose of this demonstration, we will use the Qiskit Runtime Estimator which is a primitive designed to calculate the expectation values of specified observables with respect to quantum states prepared by quantum circuits. For more information, on the packages used, visit the <a href='https://quantum.cloud.ibm.com/docs/en/api/qiskit-ibm-runtime/runtime-service'>documentation on the IBM Quantum Platform</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c056c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit.circuit.library import ZFeatureMap, z_feature_map, RealAmplitudes, EfficientSU2\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.primitives import BaseEstimatorV2\n",
    "from qiskit.quantum_info.operators.base_operator import BaseOperator\n",
    "from scipy.optimize import minimize\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "from qiskit.circuit.library import XGate\n",
    "from qiskit.transpiler import PassManager\n",
    "from qiskit.transpiler.passes import (\n",
    "    ALAPScheduleAnalysis,\n",
    "    ConstrainedReschedule,\n",
    "    PadDynamicalDecoupling,\n",
    ")\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "import copy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from qiskit.primitives import StatevectorEstimator as Estimator  # simulator\n",
    "from qiskit_ibm_runtime import (\n",
    "    EstimatorV2 as Estimator2,\n",
    "    Session,\n",
    ")\n",
    "from qiskit_machine_learning.utils import algorithm_globals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574b5104",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Account Set Up: API Key and CRN</b>\n",
    "\n",
    "- Enter your API Key and CRN.\n",
    "\n",
    "**Your Goal:** Please enter your IBM Quantum Platform API Key and CRN in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f61184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- TODO : Setup an Instance---\n",
    "# Enter your own API key and Cloud Resource Name(CRN) from the IBM Quantum Platform\n",
    "\n",
    "\n",
    "# Read token\n",
    "with open(\"tokens.json\", \"r\") as f:\n",
    "    loaded_data = json.load(f)\n",
    "api_key = loaded_data['API_key']\n",
    "crn = loaded_data['CRN_key']\n",
    "\n",
    "# Construct account object for interacting with Qiskit Runtime service\n",
    "QiskitRuntimeService.save_account(token=api_key, instance=crn, name=\"open\",overwrite=True, set_as_default=True)\n",
    "\n",
    "\n",
    "# service = QiskitRuntimeService(name=\"open\")\n",
    "# service.saved_accounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a backend list - with access to \n",
    "service = QiskitRuntimeService()\n",
    "print(\"Available backends:\")\n",
    "for backend in service.backends(simulator=False):\n",
    "    print(backend.name)\n",
    "\n",
    "avail_backend =service.least_busy(simulator=False)\n",
    "print(f\"\\n least busy backend {avail_backend}\")\n",
    "\n",
    "# backend = service.backend(\"ibm_torino\")\n",
    "backend = avail_backend\n",
    "print(f\"We are using the {backend.name} quantum computer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92a7d9b",
   "metadata": {},
   "source": [
    "#### 0.3. Overview of the QML Pipeline Adapted from Qiskit Patterns<a id=\"introduction\"></a>\n",
    "\n",
    "In this practical, we will follow an adapted version of the Qiskit Pattern to perform supervised classification by:\n",
    "1. Loading the classical $\\texttt{iris\\_dataset}$ and encoding it to quantum information.\n",
    "2. Generate and adjust the variational/parameterized quantum circuit (PQC) for our quantum neural network (QNN).\n",
    "3. Use Qiskit Primitives on the trained QNN to predict the iris species.\n",
    "4. Explore ways to scale the classification problem.\n",
    "\n",
    "Subroutines involved in each step are included in Figure 0.2., illustrating the full QML pipeline for classifying irises into three groups. For each step, we provide a brief mathematical description supporting our implementations of the Qiskit functions that we will be employing in our classical-quantum classification algorithm.\n",
    "<p style=\"text-align:center;\">\n",
    "    <img src=\"images/qml_workflow_05.png\" />\n",
    "</p>\n",
    "<p style=\"text-align:center;\">\n",
    "    Figure 0.2. illustrating the framework for classifying iris species using a QNN. \n",
    "</p>\n",
    "\n",
    "The illustration highlights how current QML pipelines combine classical and quantum information processing methods to perform the classification. The QML pipeline includes a classical-to-quantum conversion step in which classical data is mapped into quantum states, as illustrated in the diagram. \n",
    "\n",
    "The encoded data is passed through a trainable variational quantum circuit, also known as an ansatz. This is a parameterized quantum circuit that can be trained to learn patterns in the data. The ansatz typically consists of a series of quantum gates with adjustable parameters, which are optimized during training to minimize a loss function. The goal is to find the optimal parameters that enable the circuit to accurately process the input data and produce the desired output.\n",
    "\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ad7d8",
   "metadata": {},
   "source": [
    "### 1. Loading the Iris Dataset <a id=\"cml\"></a>\n",
    "Firstly, we load the the Iris dataset from the $\\texttt{sklearn.dataset}$ module. We then explore the data using visualization techniques to construct an intuitive picture of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a982755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the Iris data set from the sklearn module\n",
    "iris_dataset = datasets.load_iris()\n",
    "\n",
    "# Print dataset description\n",
    "print(iris_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcf2741",
   "metadata": {},
   "source": [
    "We can highlight a few interesting observations from this dataset description:\n",
    "\n",
    "- There are 150 samples (instances) in the dataset.\n",
    "- There are four features (attributes) for each class.\n",
    "- There are three labels (classes) in the dataset.\n",
    "- The dataset is perfectly balanced, as there are the same number of samples (50) in each class.\n",
    "- We can see features are not normalized, and their value ranges are different, e.g., $[4.3, 7.9]$ and $[0.1, 2.5]$ for sepal length and petal width, respectively. So, transforming the features to the same scale may be helpful.\n",
    "- As stated in the table above, feature-to-class correlation in some cases is very high; this may lead us to think that our model should cope well with the dataset.\n",
    "\n",
    "We only examined the dataset description, but additional properties are available in the `iris_data` object. Now we are going to work with features and labels from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79244a3d",
   "metadata": {},
   "source": [
    "##### A. Data Analysis and Description <a id=\"data_analysis\"></a>\n",
    "\n",
    "For this demonstration, we define the classical $\\texttt{iris\\_dataset}$ as a set $X$ consisting of $M=4$ data vectors corresponding to each feature, given by, $\\begin{align} X & = \\{\\vec{x}^{(j)} |j \\in [M]\\} \\nonumber \\end{align}$ where set $X = 150$ each with four attributes, the sepal length, sepal width, petal length and petal width, respectively.\n",
    "\n",
    "To improve the accuracy of the classical-to-quantum conversion, the set $M$ of features needs to be prepared for mapping to quantum data such that information is not lost and the performance of the model is not compromised. This requires that we formulate a clear understanding of the classical data so that we can curate optimal quantum circuits in the QNN. \n",
    "\n",
    "The code below is used to analyse our data using tables and graphical representations. We also leverage $\\texttt{sklearn}$ functions to extract the features and target names for our model. These features are what we will be encoding to a quantum circuit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a6c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature desciption\n",
    "features = iris_dataset.data\n",
    "labels = iris_dataset.target\n",
    "\n",
    "df = pd.DataFrame(iris_dataset.data, columns=iris_dataset.feature_names)\n",
    "df[\"class\"] = pd.Series(iris_dataset.target)\n",
    "\n",
    "sns.pairplot(df, hue=\"class\", palette=\"tab10\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aadabdb",
   "metadata": {},
   "source": [
    "Plots show that feature values range between 1 and 8 cm. To ensure optimal model performance, we use min-max normalization to rescale the feature vectors of the dataset $X$ before encoding. This simple transformation to represent all features on the same scale. Min-max normalisation takes the ratio of the difference between a datum point $x_{k}^{(i)}$ and the minimum entry in the data vector $\\vec{x}^{(j)}_k$ to the difference between the maximum and minimum entries over the $M$ data vectors in the dataset $X$. Mathematically, we can write express min-max normalisation as\n",
    "$\\begin{align}x^{'(i)}_{k} & = \\frac{x^{(i)}_k - \\min{\\{x^{(j)}_k|\\vec{x}^{(j)}\\in [X]\\}}}{\\max{\\{x^{(j)}_k|\\vec{x}^{(j)}\\in [X]\\}} - \\min{\\{x^{(j)}_k|\\vec{x}^{(j)}\\in [X]}\\}}\\nonumber\\end{align}$\n",
    "which produces values that fall between 0 and 1.\n",
    "\n",
    "We can use `MinMaxScaler` from scikit-learn to perform this. The code in the cell normalizes the feature vectors by mapping the data onto a range $[0, 1]$. When encoding data to quantum phase information, as in the case of our ZFM implementation, we rescale feature vectors as $\\vec{x}_{i}^{(j)}\\in (0, 2\\pi]$.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b0ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = MinMaxScaler().fit_transform(features)\n",
    "df_normalized = pd.DataFrame(features, columns=iris_dataset.feature_names)\n",
    "df_normalized[\"class\"] = pd.Series(iris_dataset.target)\n",
    "sns.pairplot(df_normalized, hue=\"class\", palette=\"tab10\")\n",
    "df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ab77f",
   "metadata": {},
   "source": [
    "Plots of the normalized data vectors in $X$ confirm that we have successfully rescaled the classical data values to fall within a unit circle. A close look at the plots shows that shape of the data points is preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e1f8f",
   "metadata": {},
   "source": [
    "##### B. Splitting Data <a id=\"data_split\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed744f",
   "metadata": {},
   "source": [
    "We can now split our normalized dataset into training and testing sets so that the model can be evaluated with unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_globals.random_seed = 123\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features, labels, train_size=0.8, random_state=algorithm_globals.random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e9e55c",
   "metadata": {},
   "source": [
    "As a golden measure, we train a classical Support Vector Classifier (SVC) using the $\\texttt{SVC}$ class from the $\\texttt{sklearn.svm}$ module and evaluate the performance of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fbfb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC()\n",
    "_ = svc.fit(train_features, train_labels)  # suppress printing the return value\n",
    "train_score_c4 = svc.score(train_features, train_labels)\n",
    "test_score_c4 = svc.score(test_features, test_labels)\n",
    "\n",
    "print(f\"Classical SVC on the training dataset: {train_score_c4:.2f}\")\n",
    "print(f\"Classical SVC on the test dataset:     {test_score_c4:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99102dae",
   "metadata": {},
   "source": [
    "The SVC class implements a Support Vector Machine model which is known to perform well on the Iris dataset. Although we compare the results at the end of this pipeline, researchers must be careful to ensure that the problem is suitable for applications of quantum subroutines during assessment of the solution. QML is suitable for more complex datasets which can be represented in Hilbert space without losing information about the structure of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801f256",
   "metadata": {},
   "source": [
    "#### 2. Training a Quantum Machine Learning Model <a id=\"prep\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d14a767",
   "metadata": {},
   "source": [
    "As an example of a quantum model, we'll train a QNN using an Estimator. This involves preparing the quantum circuit, using an Estimator instance to get the observable's expectation value (the network's output), and then using a classical loss function and gradient-based optimization to adjust the parameters until the loss is minimized. \n",
    "\n",
    "But before we train a model, let's examine what comprises the QNN model. Two of its central elements are the feature map and ansatz. \n",
    "\n",
    "Careful considerations have to be made when constructing a training ansatz in order for it to align to the problem or data. The considerations include:\n",
    "\n",
    "* Circuit depth: to prevent excessive hardware errors, we must ensure that we do not perform more operations than possible. \n",
    "* Parametrized circuit: we must decide on whether parameters of single or entangling gates should be varied.\n",
    "* Number of Parameters: we must choose the number of parameters such that the overhead of impelementing parametrized quantum gates is reduced.\n",
    "\n",
    "The a QNN model pipeline is illustrated in Figure 2.1. below.\n",
    "\n",
    "<p>\n",
    "    <img src=\"images/qnn_vqc_illustration.png\" />\n",
    "</p>\n",
    "<p style=\"text-align:center;\">\n",
    "    Figure 2.1. An example of a hybrid quantum framework visualizing the quantum circuit, integration of FM with ansatz and optimisation.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e77192b",
   "metadata": {},
   "source": [
    "##### A. Data Encoding Using the ZFM <a id=\"data_encoding\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c0670",
   "metadata": {},
   "source": [
    "A data encoding scheme is technique that converts information from one domain to another by converting datapoints that were sampled classically to Hilbert spaces of a quantum computer. There are many such data encoding schemes that can be used to map our classical dataset for quantum processing unit (QPU) execution. The fundamental encoding schemes used in constructing more complex mappings include:\n",
    "* Basis Encoding\n",
    "* Amplitude Encoding\n",
    "* Angle Encoding\n",
    "* Phase Encoding\n",
    "\n",
    "For example, dense angle encoding combines angle and phase encoding to facilitate a mapping of two feature values to a single qubit. Similarly, the ZFM extends concepts of phase encoding to include alternating layers of Hadamard and phase gate layers. Given a data vector $\\vec{x}$ with $N$ features, the quantum circuit that performs the feature mapping is represented as a unitary operator $U(\\vec{x})$ that acts on the initial qubit ground state $\\ket{0}^{\\otimes N}$, i.e.,\n",
    "$\\begin{align}U(\\vec{x})\\ket{0}^{\\otimes N} & = \\ket{\\phi(\\vec{x})}\\nonumber\\end{align}$\n",
    "where $\\ket{\\phi(\\vec{x})}$ is the mapping $\\phi$ of data vector $\\vec{x}$ consisting of alternating layers of single-qubit gates.\n",
    "\n",
    "The unitary matrix $U_{ZFM}(\\vec{x})$ for the ZFeatureMap (ZFM) is expressed as:\n",
    "\n",
    "$$U_{ZFM}(\\vec{x}) = \\left(\\bigotimes_{k=1}^{N}P(\\vec{x}_k)\\right)H^{\\otimes N}$$\n",
    "\n",
    "For the Iris dataset with 4 features, this becomes:\n",
    "\n",
    "$$U_{ZFM}(\\vec{x}) = [P(\\vec{x}_1)\\otimes P (\\vec{x}_2)\\otimes P(\\vec{x}_3)\\otimes P(\\vec{x}_4)]H^{\\otimes 4}$$\n",
    "\n",
    "Here:\n",
    "\n",
    "- $P(\\vec{x}_k) = \\begin{pmatrix} e^{i \\vec{x}_k} & 0 \\\\ 0 & e^{-i \\vec{x}_k} \\end{pmatrix}$ is a phase gate applied to each qubit.\n",
    "- $H^{\\otimes N}$ is the Hadamard gate applied to each qubit.\n",
    "\n",
    "The resulting quantum circuit is applied iteratively for $r$ repetitions to generate a final product state. The code below applies the built-in ZFM Qiskit class which takes in the same number of qubits as the number entries in each feature vector. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the features using an ZFeatureMap\n",
    "num_features = features.shape[1]\n",
    "feature_map = ZFeatureMap(feature_dimension=num_features)\n",
    "\n",
    "# Visualize the circuit\n",
    "feature_map.decompose().draw(output='mpl', fold=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468bf087",
   "metadata": {},
   "source": [
    "If you look closely at the feature map diagram, you will notice parameters `x[0], ..., x[3]`. These are placeholders for our features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805316f4",
   "metadata": {},
   "source": [
    "##### B. Parameterized Quantum Circuit <a id=\"ansatz\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d350ca-a6b5-432e-b019-1a7464bf21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = num_features\n",
    "\n",
    "# Using RealAmplitudes Ansatz for encoding\n",
    "ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
    "# ansatz = EfficientSU2(num_qubits=num_features, reps=3)\n",
    "\n",
    " \n",
    "# Draw the circuit\n",
    "ansatz.decompose().draw(\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c23122",
   "metadata": {},
   "source": [
    "In the first layer of the QNN ansatz circuit, each  qubit is rotated around the $y$-axis by the parameter $\\theta$. This is to say that the single-qubit R<sub>Y</sub> gate is parametrised, the unitary matrix operation given by\n",
    "$\\begin{align}R_Y & = \\left(\\begin{matrix} \\cos(\\frac{\\theta}{2}) & -\\sin(\\frac{\\theta}{2}) \\\\ \\sin(\\frac{\\theta}{2}) & \\cos(\\frac{\\theta}{2})\\end{matrix}\\right)\\nonumber\\end{align}$\n",
    "Note that when $\\theta = \\pi$, applying a Y gate effectively affects the qubit state and introduces a phase shift of $180\\degree$. \n",
    "\n",
    "In second layer, adjacent qubits are entangled using the $\\texttt{CNOT}$ gate. Recall that we can represent the results of a $\\texttt{CNOT}$ gate using a Truth Table as shown in table 2.1. below.\n",
    "<p style=\"text-align:center;\">\n",
    "    <img src=\"images/cnot_truth_table.png\" />\n",
    "</p>\n",
    "<p style=\"text-align:center;\">\n",
    "    Table 2.1. Truth table for CNOT gate showing the control, target and resultant qubit states.\n",
    "</p>\n",
    "\n",
    "Pay attention to the repetitive structure of the ansatz circuit. We define the number of these repetitions using the `reps` parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12a7ce-1428-4966-a4a9-f2e32d0da946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the ZFM with Ansatz\n",
    "# cr = ClassicalRegister(1, name=\"cr\")\n",
    "qnn_vqc = QuantumCircuit(QuantumRegister(num_qubits))\n",
    "qnn_vqc.compose(feature_map, range(num_qubits), inplace=True)\n",
    "qnn_vqc.compose(ansatz, range(num_qubits), inplace=True)\n",
    " \n",
    "# Display the circuit\n",
    "qnn_vqc.decompose().draw(\"mpl\", style=\"clifford\", fold=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2832c26",
   "metadata": {},
   "source": [
    "To interpret the results of the full circuit classically, we require an observable that produces an expectation value. The Qiskit SDK offers the Estimator which can be used to amalgamate quantum states such that we can perform measurements on a subset of the quantum kernel space produced by the QNN. Alternatively, we can use the $\\texttt{EstimatorV2}$ to measure some attribute from each qubit by applying an I, X, Y or Z operator to each qubit. In this case, we will estimate the expectation value by computing the number of counts and dividing them by the number of executed shots. This is performed in the code below where where we use a function to run a foward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the QNN function for later\n",
    "def forward_qnn(\n",
    "    qnn_qc: QuantumCircuit,\n",
    "    theta_params: np.ndarray,\n",
    "    weight_params: np.ndarray,\n",
    "    estimator: BaseEstimatorV2,\n",
    "    observable: BaseOperator,\n",
    ") -> np.ndarray:\n",
    "    \n",
    "    num_samples = theta_params.shape[0]\n",
    "    weights = np.broadcast_to(weight_params, (num_samples, len(weight_params)))\n",
    "    params = np.concatenate((theta_params, weights), axis=1)\n",
    "    pub = (qnn_qc, observable, params)\n",
    "    job = estimator.run([pub])\n",
    "    result = job.result()[0]\n",
    "    expectation_values = result.data.evs\n",
    " \n",
    "    return expectation_values\n",
    "\n",
    "\n",
    "# Define the Z operator observable which produces -1, 0, 1\n",
    "observable = SparsePauliOp.from_list([(\"ZX\" * (int(num_qubits/2)), 1)])\n",
    "np.random.seed(42)\n",
    "weight_params = np.random.rand(len(ansatz.parameters)) * 2 * np.pi\n",
    "qnn_vqc.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a427fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "objective_func_vals = []\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f7542c",
   "metadata": {},
   "source": [
    "We apply gradient-based loss function which takes in the labels predicted by our model and the groundtruth labels before returning the mean squared errror (MSE). We also apply a function that takes in the PQC parameters as inputs for use by the COBYLA classical optimiser which trains the model by sampling the dynamic weights to decrease the MSE. The result from these functions are used to indicate the accuracy of our QNN. Note that classical deep learning frameworks use a similar technique to in gradient-based techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "vqc = qnn_vqc\n",
    "observables = observable\n",
    "input_params = train_features\n",
    "target = train_labels\n",
    "estimator = Estimator()\n",
    "gradient = []\n",
    "iter = 0\n",
    "\n",
    "def loss(predict: np.ndarray, target: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "     Loss function for calculating the MSE.\n",
    "    \"\"\"\n",
    "    if len(predict.shape) <= 1:\n",
    "        return ((predict - target) ** 2).mean()\n",
    "    else:\n",
    "        raise AssertionError(\"input should be 1d-array\")\n",
    "\n",
    "def loss_weights(weight_params: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Cost function for use by classical optimiser.\n",
    "    \"\"\"\n",
    "    predictions = forward_qnn(\n",
    "        qnn_qc=vqc,\n",
    "        theta_params=input_params,\n",
    "        weight_params=weight_params,\n",
    "        estimator=estimator,\n",
    "        observable=observables,\n",
    "    )\n",
    " \n",
    "    cost = loss(predict=predictions, target=target)\n",
    "    objective_func_vals.append(cost)\n",
    "    gradient.append(cost)\n",
    " \n",
    "    global iter\n",
    "    if iter % 50 == 0:\n",
    "        print(f\"Iter: {iter}, loss: {cost}\")\n",
    "    iter += 1\n",
    " \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a41075",
   "metadata": {},
   "source": [
    "### 3. Optimising the Problem for Quantum Execution <a id=\"optimise\"></a>\n",
    "\n",
    "IBM Quantum systems have different properties such as single and two-qubit gate error rates, read-out rates and qubit coupling maps. In this step of our pipeline, we select the least-busy quantum system for execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1686c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a real backend whith low waiting times\n",
    "backend = service.least_busy(operational=True, simulator=False)\n",
    "print(backend.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06bc03",
   "metadata": {},
   "source": [
    "The Qiskit SDK allows us to optimise a logical quantum circuit for QPU execution using a preset pass manager based on the layout of physical qubits on the available quantum system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b887ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = backend.target\n",
    "# Construct standalone PassManager for handling task scheduling\n",
    "pass_manager = generate_preset_pass_manager(target=target, optimization_level=3)\n",
    "pass_manager.scheduling = PassManager(\n",
    "    [\n",
    "        # ALAP Schedule Pass class created with target backend\n",
    "        ALAPScheduleAnalysis(target=target),\n",
    "        # Rescheduler class for handling time resolution\n",
    "        ConstrainedReschedule(\n",
    "            acquire_alignment=target.acquire_alignment,\n",
    "            pulse_alignment=target.pulse_alignment,\n",
    "            target=target,\n",
    "        ),\n",
    "        # Pass class for dynamic decoupling in idle periods\n",
    "        PadDynamicalDecoupling(\n",
    "            target=target,\n",
    "            dd_sequence=[XGate(), XGate()],\n",
    "            pulse_alignment=target.pulse_alignment,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# Execute the defined schedule of passes to transpile your circuit for the device\n",
    "physical_qubits = pass_manager.run(qnn_vqc)\n",
    "# Mapp the obervable to the physical layout of the used device\n",
    "physical_observable = observable.apply_layout(physical_qubits.layout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ae0092",
   "metadata": {},
   "source": [
    "### 4. Executing Qiskit Primitives <a id=\"execute\"></a>\n",
    "\n",
    "We can now execute the optimized circuit on the QPU using Qiskit Primitives. We begin by debugging the circuit using a simulator to loop over the dataset for $b$ batches and $m$ epochs to train our QNN. Notice how decreasing the batch number affects the accuracy of the QNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edf8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "num_epochs = 10\n",
    "num_samples = len(train_features)\n",
    "objective_func_vals = []\n",
    "\n",
    "# Random initial weights for the ansatz. The fixed seed allows to replicate the experiment.\n",
    "# This was already set above, but you can try to change the seed to see the difference.\n",
    "# np.random.seed(42)\n",
    "# weight_params = np.random.rand(len(ansatz.parameters)) * 2 * np.pi\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range((num_samples - 1) // batch_size + 1):\n",
    "        print(f\"Epoch: {epoch}, batch: {i}\")\n",
    "        start_i = i * batch_size\n",
    "        end_i = start_i + batch_size\n",
    "        train_iris_batch = np.array(train_features[start_i:end_i])\n",
    "        train_labels_batch = np.array(train_labels[start_i:end_i])\n",
    "        input_params = train_iris_batch\n",
    "        target = train_labels_batch\n",
    "        iter = 0\n",
    "        res = minimize(\n",
    "            loss_weights, weight_params, method=\"COBYLA\", options={\"maxiter\": 100}\n",
    "        )\n",
    "        weight_params = res[\"x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af3e5f3",
   "metadata": {},
   "source": [
    "### 5. Post-Processing Results to Extract Classical Data <a id=\"post\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f433f1",
   "metadata": {},
   "source": [
    "In the final step of our adaptation of the Qiskit Pattern, we determine the training accuracy to interpret the above results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = forward_qnn(vqc, np.array(train_features), res[\"x\"], estimator, observable)\n",
    "# pred_train = forward(circuit_ibm, np.array(train_images), res['x'], estimator, observable_ibm)\n",
    " \n",
    "print(pred_train)\n",
    "# Define the ternary thresholds\n",
    "threshold_low = 0.25\n",
    "threshold_high = 0.3\n",
    "\n",
    "# Apply the thresholds to the predictions\n",
    "pred_train_labels = copy.deepcopy(pred_train)\n",
    "index = 0\n",
    "for pred in pred_train:\n",
    "    if pred < threshold_low:\n",
    "        pred_train_labels[index] = 0\n",
    "    elif pred >= threshold_low and pred < threshold_high: \n",
    "        pred_train_labels[index] = 2\n",
    "    else:\n",
    "        pred_train_labels[index] = 1\n",
    "    index+=1\n",
    "\n",
    "print(pred_train_labels)\n",
    "print(train_labels)\n",
    " \n",
    "accuracy = accuracy_score(train_labels, pred_train_labels)\n",
    "print(f\"Train accuracy: {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a9d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = forward_qnn(vqc, np.array(test_features), res[\"x\"], estimator, observable)\n",
    "# pred_test = forward(circuit_ibm, np.array(test_images), res['x'], estimator, observable_ibm)\n",
    " \n",
    "print(pred_test)\n",
    " \n",
    "# Apply the thresholds to the predictions\n",
    "pred_test_labels = copy.deepcopy(pred_test)\n",
    "index = 0\n",
    "for pred in pred_test:\n",
    "    if pred < threshold_low:\n",
    "        pred_test_labels[index] = 0\n",
    "    elif pred >= threshold_low and pred < threshold_high: \n",
    "        pred_test_labels[index] = 2\n",
    "    else:\n",
    "        pred_test_labels[index] = 1\n",
    "    index+=1\n",
    "\n",
    "print(pred_test_labels)\n",
    "print(test_labels)\n",
    " \n",
    "accuracy = accuracy_score(test_labels, pred_test_labels)\n",
    "print(f\"Test accuracy: {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd016edf",
   "metadata": {},
   "source": [
    "When we use 200 batches, the accuracy of the model exhibits moderate performance, achieving a model training accuracy of 67.5%. This prompts us to investigate potential issues, adjust the ansatz, and optimize our model. To guide our investigation, we can begin by identifying the following plausible causes:\n",
    "* We may have insufficient training iterations, implying that the process may not have been run for enough epochs.\n",
    "* The circuit architecture of the ansatz may not be optimal, leading to poor entanglement and limited classification.\n",
    "\n",
    "This means that to improve the performance of the model, we can increase the number of training epochs to ensure sufficient iterations for the optimizer to find the best parameters. We can also use a different encoding scheme and optimize the ansatz to improve entanglement to avoid overfitting. The code below is used to check for convergence in the optimization which can help us verify whether we constructed an ansatz with poor learnability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_func_vals_first = objective_func_vals\n",
    "# import matplotlib.pyplot as plt\n",
    " \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(obj_func_vals_first, label=\"Iris Dataset Ansatz\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b4d8d",
   "metadata": {},
   "source": [
    "We can check the number of features that were not classified correctly to understand how we can improve the QNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47587ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "missed = []\n",
    "for i in range(len(test_labels)):\n",
    "    if [i] != test_labels[i]:\n",
    "        missed.append(test_labels[i])\n",
    "print(len(missed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db47ad5d",
   "metadata": {},
   "source": [
    "### 6. Conclusion <a id=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cfdf0f",
   "metadata": {},
   "source": [
    "This notebook explored the potential of Quantum Machine Learning for classifying the Iris dataset. While quantum models achieved promising results, they still lag behind their classical counterparts in terms of accuracy and resource efficiency. However, the potential for future advancements in quantum hardware and algorithms suggests that quantum ML will eventually reach parity with classical ML. Quantum models achieved a training accuracy of 67.5% on the Iris dataset using four features, surpassing classical models trained on the same features. Reducing the number of features negatively impacted the performance of both classical and quantum models. In conclusion, the results suggest uantum models require further optimization for better entanglement and learnability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
